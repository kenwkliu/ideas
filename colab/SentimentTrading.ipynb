{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentTrading.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5LJauIceZmeb9iUffAMCf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUcbcj3bmUYX"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# TextBlob for Sentiment Analysis\n",
        "from textblob import TextBlob\n",
        "\n",
        "# For plotting word cloud\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "%load_ext google.colab.data_table \n",
        "\n",
        "\n",
        "# combine multiple words into one single word\n",
        "# e.g. very good -> very_good\n",
        "def combineWord(words):\n",
        "  combined = \"\"\n",
        "  for word in words:\n",
        "    combined += word + \"_\"\n",
        "\n",
        "  return combined[:len(combined)-1]\n",
        "\n",
        "\n",
        "# get the sentiment polarity and assessment from Textblob\n",
        "def getSentiments(content):\n",
        "  tb = TextBlob(content)\n",
        "  assessmentsList = []\n",
        "\n",
        "  for assessments in tb.sentiment_assessments.assessments:\n",
        "    assessmentsList.append((combineWord(assessments[0]), assessments[1]))\n",
        "\n",
        "  return tb.polarity, assessmentsList\n",
        "\n",
        "\n",
        "def getCount(countDict, word):\n",
        "\tif word in countDict:\n",
        "\t\treturn countDict[word] + 1\n",
        "\telse:\n",
        "\t\treturn 1\n",
        "\n",
        "\n",
        "def plotWordCloud(freqDict, numWords):\n",
        "  WIDTH, HEIGHT = 800, 600\n",
        "  BG_COLOR = \"black\" # white\n",
        "\n",
        "  wordcloud = WordCloud(max_words=numWords, stopwords='', width=WIDTH, height=HEIGHT, background_color=BG_COLOR).fit_words(freqDict)  \n",
        "  plt.figure(figsize=[15,10])\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbyBDATNmfuM"
      },
      "source": [
        "# Sentiment analysis by TextBlob\n",
        "# polarity is a float within the range [-1.0, 1.0] where -1 is very negative and 1.0 is very positive\n",
        "# subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective\n",
        "# Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information\n",
        "\n",
        "sentence = 'This class is interesting'\n",
        "\n",
        "print(sentence)\n",
        "tb = TextBlob(sentence)\n",
        "print('polarity=', tb.polarity)\n",
        "print('subjectivity=', tb.subjectivity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k_ryf7Gmsaf"
      },
      "source": [
        "# Textblob is rule and pattern based.\n",
        "# https://planspace.org/20150607-textblob_sentiment/\n",
        "# https://github.com/sloria/TextBlob/blob/eb08c120d364e908646731d60b4e4c6c1712ff63/textblob/en/en-sentiment.xml\n",
        "# <word form=\"interesting\" wordnet_id=\"a-01343918\" pos=\"JJ\" sense=\"arousing or holding the attention\" polarity=\"0.5\" subjectivity=\"0.5\" intensity=\"1.0\" confidence=\"0.9\" />\n",
        "# pos=\"JJ\" (adjective)\n",
        "\n",
        "tb.sentiment_assessments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgxy1NuEOOW4"
      },
      "source": [
        "# Handle “modifier” such as \"very\"\n",
        "# <word form=\"very\" wordnet_id=\"r-00031899\" pos=\"RB\" sense=\"used as intensifier\" polarity=\"0.2\" subjectivity=\"0.3\" intensity=\"1.3\" confidence=\"0.9\" />\n",
        "# \"very\" intensity=\"1.3\"\n",
        "sentence = 'This class is very interesting'\n",
        "\n",
        "print(sentence)\n",
        "tb = TextBlob(sentence)\n",
        "print('polarity=', tb.polarity)\n",
        "tb.sentiment_assessments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RNwYnHwN97s"
      },
      "source": [
        "# Handle “negation” such as \"not\"\n",
        "# self.negations   = kwargs.get(\"negations\", (\"no\", \"not\", \"n't\", \"never\"))\n",
        "sentence = 'This class is not interesting'\n",
        "\n",
        "print(sentence)\n",
        "tb = TextBlob(sentence)\n",
        "print('polarity=', tb.polarity)\n",
        "tb.sentiment_assessments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ercxzRq4m51_"
      },
      "source": [
        "# Handle mood (Emoticons)\n",
        "# https://github.com/sloria/TextBlob/blob/dev/textblob/_text.py#L223\n",
        "# (\"smile\", +0.50): set((\">:)\", \":-)\", \":)\", \"=)\", \"=]\", \":]\", \":}\", \":>\", \":3\", \"8)\", \"8-)\")),\n",
        "sentence = 'oh :)'\n",
        "\n",
        "print(sentence)\n",
        "tb = TextBlob(sentence)\n",
        "print('polarity=', tb.polarity)\n",
        "tb.sentiment_assessments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwraN1s3mxHa"
      },
      "source": [
        "# Handle irony (sarcasm)\n",
        "sentence = \"You're really good (!)\"\n",
        "\n",
        "print(sentence)\n",
        "tb = TextBlob(sentence)\n",
        "print('polarity=', tb.polarity)\n",
        "tb.sentiment_assessments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPUhgcZlm_rZ"
      },
      "source": [
        "# Understand profanity (dirty word) \n",
        "# Don't understand punctuation (probably the punctuations are removed in the text pre-processing step)\n",
        "print(TextBlob(\"he is a moron\").sentiment_assessments)\n",
        "print(TextBlob(\"who is the moron?\").sentiment_assessments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN_jzFuWN-yp"
      },
      "source": [
        "# Averaging the sentiment scores for the overall polarity: \"interesting\" and \"tough\"\n",
        "sentence = \"This class is interesting but the content is too tough\"\n",
        "\n",
        "print(sentence)\n",
        "tb = TextBlob(sentence)\n",
        "print('polarity=', tb.polarity)\n",
        "tb.sentiment_assessments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTN9NRQYewo7"
      },
      "source": [
        "# When a word (such as \"mild\") has different meaning in context, again use averaging\n",
        "#<word form=\"mild\" cornetto_synset_id=\"n_a-518871\" wordnet_id=\"a-01893510\" pos=\"JJ\" sense=\"humble in spirit or manner\" polarity=\"0.5\" subjectivity=\"0.5\" intensity=\"1.0\" confidence=\"0.9\" />\n",
        "#<word form=\"mild\" cornetto_synset_id=\"n_a-535263\" wordnet_id=\"a-00438332\" pos=\"JJ\" sense=\"mild and pleasant\" polarity=\"0.5\" subjectivity=\"0.5\" intensity=\"1.0\" confidence=\"0.9\" />\n",
        "#<word form=\"mild\" wordnet_id=\"a-01508719\" pos=\"JJ\" sense=\"moderate in type or degree or effect or force\" polarity=\"0.0\" subjectivity=\"0.5\" intensity=\"1.0\" confidence=\"0.9\" />\n",
        "\n",
        "sentence = 'The effect of the drug is mild'\n",
        "\n",
        "print(sentence)\n",
        "tb = TextBlob(sentence)\n",
        "print('polarity=', tb.polarity)\n",
        "tb.sentiment_assessments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX3vPQTdTueB"
      },
      "source": [
        "# Use the Apple Tweets (2016-Apr) to predict the Apple stock price daily change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOD1dvfRnDM6"
      },
      "source": [
        "# Get the tweet data source\n",
        "url = 'https://raw.githubusercontent.com/kenwkliu/ideas/master/colab/data/appleTweets.xlsx'\n",
        "appleTweets = pd.read_excel(url)\n",
        "\n",
        "appleTweets.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrEQqod1nHPb"
      },
      "source": [
        "# Show partial results\n",
        "appleTweets[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ3aTwMcnXNR"
      },
      "source": [
        "appleTweets.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qprA5jk2nZ7M"
      },
      "source": [
        "# Look at the subset of useful columns for the sentiment trading\n",
        "COLUMNS = ['Date', 'User Name', 'Tweet content', 'Following', 'Hashtags']\n",
        "appleTweetsSubset = appleTweets[COLUMNS]\n",
        "\n",
        "appleTweetsSubset[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq4nr_3dTAkU"
      },
      "source": [
        "# Count Duplicates \n",
        "print('Duplicate content count=', appleTweetsSubset[['Tweet content']].duplicated().sum())\n",
        "\n",
        "# Remove duplicate\n",
        "print(\"Original row# :\", appleTweetsSubset.shape[0])\n",
        "appleTweetsSubset = appleTweetsSubset.drop_duplicates(subset='Tweet content', keep='first')\n",
        "print(\"Row after removed duplicates# :\", appleTweetsSubset.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI1j-axpnhEk"
      },
      "source": [
        "# Filter the contents with the number of followings\n",
        "MIN_FOLLOWING = 500\n",
        "\n",
        "# Filter tweet with at least the MIN_FOLLOWING\n",
        "appleTweetsFiltered = appleTweetsSubset[(appleTweetsSubset['Following'] >= MIN_FOLLOWING)]\n",
        "appleTweetsFiltered.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Original row# :\", appleTweetsSubset.shape[0])\n",
        "print(\"Filtered row# :\", appleTweetsFiltered.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX77hBCBoDDH"
      },
      "source": [
        "# interactive table max_rows = 20000\n",
        "SHOW_NUMS = 20000\n",
        "appleTweetsFiltered[:SHOW_NUMS]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxy0PasNgJvl"
      },
      "source": [
        "# count the hastags frequencies\n",
        "hashtagsCount = {}\n",
        "\n",
        "for hashtags in appleTweetsFiltered['Hashtags']:\n",
        "  if type(hashtags) == str:\n",
        "    for hashtag in hashtags.split(\",\"):\n",
        "      tag = hashtag.strip().lower()\n",
        "      hashtagsCount[tag] = getCount(hashtagsCount, tag)\n",
        "\n",
        "hashtagsDf = pd.DataFrame.from_dict(hashtagsCount, orient='index', columns= ['count']).sort_values('count', ascending=False)\n",
        "hashtagsDf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX6HKVqGPAwu"
      },
      "source": [
        "*   Use **TextBlob** to get the sentiment **assessment** and **polarity** of each Tweet content\n",
        "*   Weight the tweets sentiment importance by the number of followings (**sentiment_weighted**)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XgFN89EoGgI"
      },
      "source": [
        "# Use TextBlob to run the tweets sentiment polarity\n",
        "appleTweetsFiltered['sentiment'], appleTweetsFiltered['assessments'] = zip(*appleTweetsFiltered['Tweet content'].apply(getSentiments))\n",
        "\n",
        "# Weight the tweets sentiment importance by the number of followings\n",
        "appleTweetsFiltered['sentiment_weighted'] = appleTweetsFiltered['sentiment'] * appleTweetsFiltered['Following']\n",
        "\n",
        "SENTIMENT_COLS = ['Tweet content', 'assessments', 'sentiment', 'Following', 'sentiment_weighted']\n",
        "appleTweetsFiltered[SENTIMENT_COLS][:SHOW_NUMS]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thmVddTO-X0q"
      },
      "source": [
        "# see the sentiment distribution histogram\n",
        "import plotly.express as px\n",
        "fig = px.histogram(appleTweetsFiltered, x=\"sentiment\", title='Sentiment Polarity Distribution', nbins=50)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu4BgDSLoV9-"
      },
      "source": [
        "# Plot the sentiment_weighted\n",
        "appleTweetsFiltered['sentiment_weighted'].plot(figsize=(12, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn4-Rk3SR1yQ"
      },
      "source": [
        "# count the positive, neutral and negative sentiment words\n",
        "positiveWordCounts = {}\n",
        "negativeWordCounts = {}\n",
        "neutralWordCounts = {}\n",
        "allWordsSentiment = {}\n",
        "\n",
        "for assessments in appleTweetsFiltered['assessments']:\n",
        "\tfor assessment in assessments:\n",
        "\t\tallWordsSentiment[assessment[0]] = assessment[1]\n",
        "\t\t\n",
        "\t\tif assessment[1] > 0:\n",
        "\t\t\tpositiveWordCounts[assessment[0]] = getCount(positiveWordCounts, assessment[0])\n",
        "\t\telif assessment[1] < 0:\n",
        "\t\t\tnegativeWordCounts[assessment[0]] = getCount(negativeWordCounts, assessment[0])\n",
        "\t\telse:\n",
        "\t\t\tneutralWordCounts[assessment[0]] = getCount(neutralWordCounts, assessment[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3OMYNJkTU3d"
      },
      "source": [
        "#Plot the positive WordCloud\n",
        "plotWordCloud(positiveWordCounts, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7hVF6ZzdwnK"
      },
      "source": [
        "#Plot the negative WordCloud\n",
        "plotWordCloud(negativeWordCounts, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJVFnTwr_Q7C"
      },
      "source": [
        "#Plot the neutral WordCloud\n",
        "plotWordCloud(neutralWordCounts, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0TyzAnlAOJW"
      },
      "source": [
        "# use dataframe table to see all the sentiment poloarity and counts\n",
        "allWordCountsDict = {**positiveWordCounts, **negativeWordCounts, **neutralWordCounts}\n",
        "wordCountsDictDf = pd.DataFrame.from_dict(allWordCountsDict, orient='index', columns=['count'])\n",
        "wordsSentimentDf = pd.DataFrame.from_dict(allWordsSentiment, orient='index', columns=['sentiment'])\n",
        "allWordsDf = wordsSentimentDf.merge(wordCountsDictDf, left_index=True, right_index=True)\n",
        "allWordsDf.sort_values(by=['count'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3znaSATmoxUa"
      },
      "source": [
        "# Group the weighted sentiment by Date for matching the stock daily change\n",
        "\n",
        "# Convert Date string to datetime to match with the stock daily change later\n",
        "appleTweetsFiltered['Date'] = pd.to_datetime(appleTweetsFiltered['Date'])\n",
        "\n",
        "aggregateSentiments = appleTweetsFiltered.groupby(['Date']).sum()[['sentiment_weighted']]\n",
        "aggregateSentiments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDeetavDo3X1"
      },
      "source": [
        "# get stocks daily data (OHLCV) from Yahoo\n",
        "import pandas_datareader.data as web\n",
        "from datetime import datetime\n",
        "\n",
        "start = datetime(2016, 4, 2) \n",
        "end = datetime(2016, 4, 30) \n",
        "stock= web.DataReader('AAPL', 'yahoo', start=start, end=end)\n",
        "stock"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PIdu3aho6Gs"
      },
      "source": [
        "# calculate the stock daily change\n",
        "stock['change'] = (stock['Close'] - stock['Open']) / stock['Open']\n",
        "stock[['Open', 'Close', 'change']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACXQ5DwUo-hA"
      },
      "source": [
        "# Merge the daily stock price change with the sentiments\n",
        "# Use the daily aggregated sentiment to predict the daily price change\n",
        "merged = stock.merge(aggregateSentiments, on='Date', how='left')[['change', 'sentiment_weighted']]\n",
        "merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aUSfzyvpCRa"
      },
      "source": [
        "# Scale the unit to -1 to 1\n",
        "scaler = MinMaxScaler((-1, 1))\n",
        "merged['changes'] = scaler.fit_transform(merged[['change']])\n",
        "merged['sentiments'] = scaler.fit_transform(merged[['sentiment_weighted']])\n",
        "scaled = merged[['changes', 'sentiments']]\n",
        "scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Gx3jPrpE1a"
      },
      "source": [
        "scaled.plot(figsize=(15, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5_d7UVVpHw9"
      },
      "source": [
        "# shows the correlation\n",
        "scaled.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQoMv8jMR_lj"
      },
      "source": [
        " **Try sentiments with different date lags**\n",
        "\n",
        "*   Sentiment shift backwards -> Current day sentiments predicts next day stock price change (**predictive_sentiment**)\n",
        "*   Sentiment shift forwards -> Current day sentiments reflects yesterday's price change (**reactive_sentiment**)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz0ZWY-CpLMm"
      },
      "source": [
        "# Sentiment shift backwards -> Current day sentiments predicts next day stock price change (predictive)\n",
        "scaled['predictive_sentiment'] = merged['sentiments'].shift(-1)\n",
        "\n",
        "# Sentiment shift forwards -> Current day sentiments reflects yesterday's price change (reactive)\n",
        "scaled['reactive_sentiment'] = merged['sentiments'].shift(1)\n",
        "scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNJJi300pNwX"
      },
      "source": [
        "scaled.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFy2FdEcSue1"
      },
      "source": [
        "**Notes**\n",
        "* **Filter contents** with different conditions or use hashtags to get more \"relevant\" tweets to the company\n",
        "* Use different **weightings** apart from the Followings\n",
        "* Take sentiment **subjectivity** into account (maybe more subjective is more important)\n",
        "* Is the **coverage** enough? Add different data source of sentiment\n",
        "* Use a better **sentiment analysis engine** (e.g. tailored made with social media content and stock trading)\n",
        "* Try with **different date lags** and compares the close price changes rather than open-close changes\n",
        "* Price change comparing to **sentiment change** rather than raw sentiment scores\n",
        "* Use sentiment **moving average** or long/short term sentiment cross over\n",
        "* Combine with other **technical indicators** such as stock price moving average\n",
        "* Combine with other Machine Learned **signals** or trends"
      ]
    }
  ]
}