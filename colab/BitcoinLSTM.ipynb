{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BitcoinLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBsmUMCLKkcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# univariate LSTM example\n",
        "# https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
        "\n",
        "import datetime\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjkcyVi_Ljoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CryptoData(symbol, frequency, start=0):\n",
        "    #Params: String symbol, int frequency = 300,900,1800,7200,14400,86400\n",
        "    #Returns: df from first available date\n",
        "    url ='https://poloniex.com/public?command=returnChartData&currencyPair='+symbol+'&end=9999999999&period='+str(frequency)+'&start='+str(start)\n",
        "    df = pd.read_json(url)\n",
        "    df.set_index('date',inplace=True)\n",
        "    return df\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "\n",
        "def getPrediction(lstm, raw_seq, index, n_steps, n_features):\n",
        "  x_seq = raw_seq[index-n_steps : index]\n",
        "  x_seq = x_seq.reshape(1, n_steps, n_features)\n",
        "  \n",
        "  yhat = lstm.predict(x_seq)\n",
        "  y = raw_seq[index]\n",
        "  \n",
        "  return x_seq, yhat, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFQ40gGWMWNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "startDate = int((datetime.datetime.strptime('1/1/2018', \"%d/%m/%Y\").timestamp()))\n",
        "testSymbol = 'USDT_BTC' #bitCoin\n",
        "# frequency = 86400s which is 1 day\n",
        "df = CryptoData(testSymbol, 86400, startDate)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8v7_048Mhfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['close'].plot(figsize = (16,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLLr5nkKDn9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define input sequence and no. of features\n",
        "raw_seq = df['close'].values\n",
        "n_features = raw_seq.ndim\n",
        "data_size = len(raw_seq)\n",
        "\n",
        "print(\"n_features:\", n_features) \n",
        "print(\"data_size:\", data_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbXL6uaAFZad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ratio = 0.8\n",
        "train_size = round(train_ratio * data_size)\n",
        "train_seq = raw_seq[:train_size]\n",
        "test_seq = raw_seq[train_size:]\n",
        "\n",
        "print(\"train_size:\", train_size)\n",
        "print(\"test_size:\", data_size-train_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GOnoTg5GDv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose a number of time steps\n",
        "n_steps = 7\n",
        "\n",
        "# split into training samples\n",
        "x_train, y_train = split_sequence(train_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] to [samples, timesteps, features]\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHOqUujHIPK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN4siezOITam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enKZdch6IWxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LTSM model\n",
        "# The number of hidden neurons in LSTM does not directly relate to the timestep \n",
        "model = Sequential()\n",
        "model.add(LSTM(32, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aATHwKc6zlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n",
        "# The lstm (LSTM) Param # = g * [h(h+i) + h]\n",
        "# where g is number of gates and LSTM = 4\n",
        "# h = no. of LSTM hidden neurons\n",
        "# i = the dimension of input (feature)\n",
        "# 4 * (32 (32 + 1) + 32) = 4352"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fki5pgeHL_GU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit model\n",
        "model.fit(x_train, y_train, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnUO2zbnJX21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict the next day\n",
        "index = train_size\n",
        "x_seq, yhat, y = getPrediction(model, raw_seq, index, n_steps, n_features)\n",
        "\n",
        "print(x_seq)\n",
        "print(\"Predicted:\", yhat[0][0])\n",
        "print(\"Actual:\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOike2xcMse5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict the rest of the series and comparing to the test set\n",
        "# Each prediction is based on the \"actual\" observation from the past days\n",
        "# Another way is to use multi-step ahead output or\n",
        "# use the predicted values as new observations to further predict the rest of the series\n",
        "\n",
        "predictedList = []\n",
        "actualList = []\n",
        "\n",
        "for i in range(train_size, data_size):\n",
        "  x_seq, yhat, y = getPrediction(model, raw_seq, i, n_steps, n_features)\n",
        "  predictedList.append(yhat[0][0])\n",
        "  actualList.append(y)\n",
        "\n",
        "for i in range(len(predictedList)):\n",
        "  print(\"Predicted:\", round(predictedList[i], 2),\n",
        "       \" Actual:\", round(actualList[i], 2),\n",
        "       \" Error:\", round(actualList[i]-predictedList[i], 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx-3QSR6OQxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.plot(predictedList, label=\"Predicted\")\n",
        "plt.plot(actualList, label=\"Actual\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}