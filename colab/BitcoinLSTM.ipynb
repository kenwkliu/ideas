{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BitcoinLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBsmUMCLKkcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# univariate LSTM example\n",
        "# https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
        "\n",
        "import datetime\n",
        "import statistics as stats\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjkcyVi_Ljoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SCREEN_X, SCREEN_Y = 12, 8\n",
        "\n",
        "def CryptoData(symbol, frequency, start=0):\n",
        "    #Params: String symbol, int frequency = 300,900,1800,7200,14400,86400\n",
        "    #Returns: df from first available date\n",
        "    url ='https://poloniex.com/public?command=returnChartData&currencyPair='+symbol+'&end=9999999999&period='+str(frequency)+'&start='+str(start)\n",
        "    df = pd.read_json(url)\n",
        "    df.set_index('date',inplace=True)\n",
        "    return df\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "\n",
        "def getPrediction(lstm, raw_seq, index, n_steps, n_features):\n",
        "  x_seq = raw_seq[index-n_steps : index]\n",
        "  x_seq = x_seq.reshape(1, n_steps, n_features)\n",
        "  \n",
        "  yhat = lstm.predict(x_seq)\n",
        "  y = raw_seq[index]\n",
        "  \n",
        "  return x_seq, yhat, y\n",
        "\n",
        "\n",
        "# predict the next day close as the same as today's close \n",
        "def getBasePrediction(raw_seq, index, n_steps):\n",
        "  x_seq = raw_seq[index-n_steps : index]\n",
        "  \n",
        "  yhat = x_seq[len(x_seq)-1]\n",
        "  y = raw_seq[index]\n",
        "  \n",
        "  return x_seq, yhat, y\n",
        "\n",
        "\n",
        "def roundNum(num, dp=2):\n",
        "\treturn round(num, dp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFQ40gGWMWNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "startDate = int((datetime.datetime.strptime('1/1/2018', \"%d/%m/%Y\").timestamp()))\n",
        "testSymbol = 'USDT_BTC' #bitCoin\n",
        "# frequency = 86400s which is 1 day\n",
        "df = CryptoData(testSymbol, 86400, startDate)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8v7_048Mhfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['close'].plot(figsize = (SCREEN_X, SCREEN_Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLLr5nkKDn9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define input sequence and no. of features\n",
        "# Use only the \"close\" price as the input feature\n",
        "raw_seq = df['close'].values\n",
        "n_features = raw_seq.ndim\n",
        "data_size = len(raw_seq)\n",
        "\n",
        "print(\"n_features:\", n_features) \n",
        "print(\"data_size:\", data_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbXL6uaAFZad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the data into training and test set\n",
        "train_ratio = 0.8\n",
        "train_size = round(train_ratio * data_size)\n",
        "train_seq = raw_seq[:train_size]\n",
        "test_seq = raw_seq[train_size:]\n",
        "\n",
        "print(\"train_size:\", train_size)\n",
        "print(\"test_size:\", data_size-train_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GOnoTg5GDv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose a number of time steps\n",
        "n_steps = 7\n",
        "\n",
        "# split into training samples\n",
        "x_train, y_train = split_sequence(train_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] to [samples, timesteps, features]\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHOqUujHIPK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 0\n",
        "print(x_train[index])\n",
        "print('--->', y_train[index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11H12LwUu0xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 1\n",
        "print(x_train[index])\n",
        "print('--->', y_train[index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enKZdch6IWxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LTSM model\n",
        "# The number of hidden neurons in LSTM does not directly relate to the timestep \n",
        "model = Sequential()\n",
        "model.add(LSTM(32, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aATHwKc6zlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n",
        "# The lstm (LSTM) Param # = g * [h(h+i) + h]\n",
        "# where g is number of gates and LSTM = 4\n",
        "# h = no. of LSTM hidden neurons\n",
        "# i = the dimension of input (feature)\n",
        "# 4 * (32 (32 + 1) + 32) = 4352"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fki5pgeHL_GU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit model\n",
        "history = model.fit(x_train, y_train, epochs=20)\n",
        "\n",
        "# Plot the loss\n",
        "loss = history.history['loss']\n",
        "epoch = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epoch, loss, 'r', label='Training loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnUO2zbnJX21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict the next day\n",
        "index = train_size\n",
        "x_seq, yhat, y = getPrediction(model, raw_seq, index, n_steps, n_features)\n",
        "\n",
        "predicted = yhat[0][0]\n",
        "actual = y\n",
        "error = actual - predicted\n",
        "errorP = abs(error) / predicted\n",
        "\n",
        "print(x_seq, \"\\n\")\n",
        "print(\"Predicted:\", predicted)\n",
        "print(\"Actual:\", actual)\n",
        "print(\"Error:\", error)\n",
        "print(\"Error%:\", roundNum(errorP, 4)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOike2xcMse5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict the rest of the series and comparing to the test set\n",
        "# Each prediction is based on the \"actual\" observation from the past days\n",
        "# Another way is to use multi-step ahead output or\n",
        "# use the predicted values as new observations to further predict the rest of the series\n",
        "\n",
        "predictedList = []\n",
        "actualList = []\n",
        "\n",
        "for i in range(train_size, data_size):\n",
        "  x_seq, yhat, y = getPrediction(model, raw_seq, i, n_steps, n_features)\n",
        "  predictedList.append(yhat[0][0])\n",
        "  actualList.append(y)\n",
        "\n",
        "# plot the result\n",
        "plt.figure(figsize=(SCREEN_X, SCREEN_Y))\n",
        "plt.plot(predictedList, label=\"Predicted\")\n",
        "plt.plot(actualList, label=\"Actual\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cigPrrK209Id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at the individual predictions\n",
        "lstmError = []\n",
        "lstmErrorP = []\n",
        "for i in range(len(predictedList)):\n",
        "  error = actualList[i]-predictedList[i]\n",
        "  absError = abs(error)\n",
        "  errorP = absError/actualList[i]\n",
        "  lstmError.append(absError)\n",
        "  lstmErrorP.append(errorP)\n",
        "\n",
        "  print(\"Predicted:\", roundNum(predictedList[i]),\n",
        "       \"  Actual:\", roundNum(actualList[i]),\n",
        "       \"  Error:\", roundNum(error), \n",
        "        \"->\", roundNum(errorP), sep='')\n",
        "\n",
        "print(\"--------------------------------------\")  \n",
        "print(\"Error: Total=\",roundNum(sum(lstmError)), \" Average=\",roundNum(stats.mean(lstmError)), \" Min=\",roundNum(min(lstmError)), \" Max=\",roundNum(max(lstmError)), sep='')\n",
        "print(\"Error Ratio: Average=\",roundNum(stats.mean(lstmErrorP)), \" Min=\",roundNum(min(lstmErrorP)), \" Max=\",roundNum(max(lstmErrorP)), sep='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAX7cAWD52w6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baseline comparison: predict the next day close as the same as today's close\n",
        "basePredictedList = []\n",
        "baseActualList = []\n",
        "\n",
        "for i in range(train_size, data_size):\n",
        "  x_seq, yhat, y = getBasePrediction(raw_seq, i, n_steps)\n",
        "  basePredictedList.append(yhat)\n",
        "  baseActualList.append(y)\n",
        "\n",
        "\n",
        "# look at the individual predictions\n",
        "baseError = []\n",
        "baseErrorP = []\n",
        "for i in range(len(basePredictedList)):\n",
        "  error = baseActualList[i]-basePredictedList[i]\n",
        "  absError = abs(error)\n",
        "  errorP = absError/baseActualList[i]\n",
        "  baseError.append(absError)\n",
        "  baseErrorP.append(errorP)\n",
        "\n",
        "  print(\"Predicted:\", roundNum(basePredictedList[i]),\n",
        "       \"  Actual:\", roundNum(baseActualList[i]),\n",
        "       \"  Error:\", roundNum(error), \n",
        "        \"->\", roundNum(errorP), sep='')\n",
        "\n",
        "print(\"--------------------------------------\")  \n",
        "print(\"Error: Total=\",roundNum(sum(baseError)), \" Average=\",roundNum(stats.mean(baseError)), \" Min=\",roundNum(min(baseError)), \" Max=\",roundNum(max(baseError)), sep='')\n",
        "print(\"Error Ratio: Average=\",roundNum(stats.mean(baseErrorP)), \" Min=\",roundNum(min(baseErrorP)), \" Max=\",roundNum(max(baseErrorP)), sep='')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx9w8r2sJPn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot base result\n",
        "plt.figure(figsize=(SCREEN_X, SCREEN_Y))\n",
        "plt.plot(basePredictedList, label=\"Predicted\")\n",
        "plt.plot(baseActualList, label=\"Actual\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZesDQ7OCHfZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot all results\n",
        "plt.figure(figsize=(SCREEN_X, SCREEN_Y))\n",
        "plt.plot(predictedList, label=\"LSTM\")\n",
        "plt.plot(basePredictedList, label=\"Base\")\n",
        "plt.plot(baseActualList, label=\"Actual\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}