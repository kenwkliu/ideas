{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-CIFAR-10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZwNFBl8n80S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxszAyJeoiJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict individual image\n",
        "def predictOneImage(x_test, y_test, ans, p_index):\n",
        "  first_image = x_test[p_index]\n",
        "  plt.imshow(first_image)\n",
        "  plt.show()\n",
        "\n",
        "  count = 0\n",
        "  for a in ans[p_index]:\n",
        "      print(labels[count], \"=\", round(a*100, 2))\n",
        "      count = count + 1\n",
        "      \n",
        "  print(\"------------------\")\n",
        "  print(\"True Label:\", labels[y_test[p_index][0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nw9Knu2pDFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "labels = {\n",
        "    0: \"plane\",\n",
        "    1: \"car  \",\n",
        "    2: \"bird \",\n",
        "    3: \"cat  \",\n",
        "    4: \"deer \",\n",
        "    5: \"dog  \",\n",
        "    6: \"frog \",\n",
        "    7: \"horse\",\n",
        "    8: \"ship \",\n",
        "    9: \"truck\",    \n",
        "}\n",
        "\n",
        "train_size, test_size = x_train.shape[0], x_test.shape[0]\n",
        "height, width, depth = x_train.shape[1], x_train.shape[2], x_train.shape[3]\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnIMgN1vhkA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visual the data\n",
        "index = 0\n",
        "\n",
        "print(x_train[index])\n",
        "first_image = x_train[index]\n",
        "plt.imshow(first_image)\n",
        "plt.show()\n",
        "\n",
        "print(\"Label:\", labels[y_train[index][0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5ruzRAHhptr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For Dense Neural Network\n",
        "# reshape the 32x32x3 pixels to a 3072 array\n",
        "# and normalize the number by 255\n",
        "\n",
        "dim = height * width * depth\n",
        "x_trainp = x_train.reshape(train_size, dim)\n",
        "x_testp = x_test.reshape(test_size, dim)\n",
        "\n",
        "normalize = 255\n",
        "x_trainp = x_trainp.astype('float32') / normalize\n",
        "x_testp = x_testp.astype('float32') / normalize\n",
        "\n",
        "print(x_trainp.shape[0], 'train samples')\n",
        "print(x_testp.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-dSiNisjJ1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices: one-hot encoding\n",
        "num_classes = 10\n",
        "\n",
        "y_trainp = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_testp = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Encoded Label:\", y_trainp[index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_pa50bujTKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dense NN with multiple hidden layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, activation='relu', input_shape=(dim,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObtKA1gGWd4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n",
        "# Param calculation in each layer = input * output + output bias\n",
        "# Input images = 32 * 32 * 3 = 3072\n",
        "# dense Params =  = 3072 * 64 + 64 = 196672\n",
        "# dense_1 params = 64 * 32 + 32 = 30 = 2080\n",
        "# dense_2 params = 32 * 10 + 10 = 30 = 330"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujWTiYbj0tN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 10\n",
        "\n",
        "# Set aside the first 10,000 samples as the validation set\n",
        "val_size = 10000\n",
        "x_valp = x_trainp[:val_size]\n",
        "partial_x_trainp = x_trainp[val_size:]\n",
        "\n",
        "y_valp = y_trainp[:val_size]\n",
        "partial_y_trainp = y_trainp[val_size:]\n",
        "\n",
        "history = model.fit(partial_x_trainp, partial_y_trainp,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_valp, y_valp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwnpe-bnkTpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do the prediction on test set\n",
        "score = model.evaluate(x_testp, y_testp, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "ans = model.predict(x_testp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5RKssMdkcE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict individual image\n",
        "p_index = 666\n",
        "predictOneImage(x_test, y_test, ans, p_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_TcmLOSlo9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use CNN and reshape the 32x32x3 pixels \n",
        "# and normalize the number by 255\n",
        "\n",
        "x_trainCnn = x_train.reshape(train_size, height, width, depth)\n",
        "x_testCnn = x_test.reshape(test_size, height, width, depth)\n",
        "\n",
        "x_trainCnn = x_trainCnn.astype('float32') / normalize\n",
        "x_testCnn = x_testCnn.astype('float32') / normalize\n",
        "\n",
        "print(x_trainCnn.shape[0], 'train samples')\n",
        "print(x_testCnn.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6216NjIKFxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use CNN\n",
        "cnn = Sequential()\n",
        "\n",
        "# Filter = 32, Kernel_size = 3 * 3\n",
        "cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "cnn.add(MaxPooling2D((2, 2)))\n",
        "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn.add(MaxPooling2D((2, 2)))\n",
        "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(64, activation='relu'))\n",
        "cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "plot_model(cnn, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zofs7FBKXi9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.summary()\n",
        "# Pooling Layer: There are no parameters you could learn in pooling layer. This layer is just used to reduce the image dimension size.\n",
        "# Conv layer parameters:  (n * m * l + 1) * k,  where n * m is the kernel_size, l is input filter, k is the output filter\n",
        "# conv2d = (3 * 3 * 3 + 1) * 32 = 896\n",
        "# conv2d_1 = (3 * 3 * 32 + 1) * 64 = 18496\n",
        "# conv2d_2 = (3 * 3 * 64 + 1) * 64 = 36928"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAsFpa6mLACv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set aside the first 10,000 samples as the validation set\n",
        "x_valCnn = x_trainCnn[:val_size]\n",
        "partial_x_trainCnn = x_trainCnn[val_size:]\n",
        "\n",
        "\n",
        "history = cnn.fit(partial_x_trainCnn, partial_y_trainp,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_valCnn, y_valp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtRPEUSNLxbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do the prediction on test set\n",
        "score = cnn.evaluate(x_testCnn, y_testp, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "cnnAns = cnn.predict(x_testCnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb6iYgClL1Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict individual image\n",
        "predictOneImage(x_test, y_test, cnnAns, p_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30knzvhX6_by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use pre-trained VGG Imagenet CNN layers\n",
        "\n",
        "# include_top=False: doesn't include the densely connected classifier layers on top of the network\n",
        "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(height, width, depth))\n",
        "conv_base.trainable = True\n",
        "\n",
        "# Fine-tune the last 3 convolutional layers (i.e. block5)\n",
        "# Usually fine-tune the last few convolutional layers as it's more higher level (abstract) features to the problem\n",
        "# while the first few layers are more generic and re-usable features\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name[:6] != 'block5':\n",
        "    layer.trainable = False\n",
        "\n",
        "plot_model(conv_base, show_shapes=True, show_layer_names=True)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV7gaZ9AbSCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTS9i9UY9mWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use CNN\n",
        "pModel = Sequential()\n",
        "\n",
        "pModel.add(conv_base)\n",
        "pModel.add(Flatten())\n",
        "pModel.add(Dense(64, activation='relu'))\n",
        "pModel.add(Dense(10, activation='softmax'))\n",
        "\n",
        "pModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "plot_model(pModel, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqEsAgPcbeVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pModel.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0FkNxPT-ZQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = pModel.fit(partial_x_trainCnn, partial_y_trainp,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_valCnn, y_valp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u_Cjwou-sSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do the prediction on test set\n",
        "score = pModel.evaluate(x_testCnn, y_testp, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "pAns = pModel.predict(x_testCnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WedeuqT-xMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict individual image\n",
        "predictOneImage(x_test, y_test, pAns, p_index)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}