{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSb-_6hddD1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "wnl = nltk.WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSUyuB2_dD1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _removeSymbols(text):\n",
        "    removeSymRx = re.compile('\\W')\n",
        "            \n",
        "    return re.sub(removeSymRx, \" \", text)    \n",
        "\n",
        "    \n",
        "def _stem(text):\n",
        "    stemmed_words = []\n",
        "    #  am, are, is -> be\n",
        "    # car, cars, car's, cars' -> car\n",
        "    for t in text.split():\n",
        "        lemmatized = wnl.lemmatize(t)\n",
        "        if (len(lemmatized) > 1 and lemmatized.isdigit() == False):\n",
        "            stemmed_words.append(lemmatized)\n",
        "\n",
        "    return ' '.join(stemmed_words)\n",
        "    \n",
        "\n",
        "def _subWholeText(subText, text):\n",
        "    for k, v in subText.items():\n",
        "        text = re.sub(r\"\\b%s\\b\" % k, v, text)\n",
        "        # r\"\\b%s\\b\"% enables replacing by whole word matches only\n",
        "    return text\n",
        "\n",
        "    \n",
        "def _subText(subText, text):\n",
        "    for k in subText:\n",
        "        text = text.replace(k, subText[k])\n",
        "        \n",
        "    return text\n",
        "    \n",
        "    \n",
        "def _stop(text):\n",
        "    stopped_words = []\n",
        "\n",
        "    for t in text.split():\n",
        "        if (t not in stop_words):\n",
        "            stopped_words.append(t)\n",
        "\n",
        "    return ' '.join(stopped_words)\n",
        "\n",
        "\n",
        "def process(text):\n",
        "    # remove symbols\n",
        "    text = _removeSymbols(text)\n",
        "\n",
        "    # To lower case\n",
        "    text = text.lower()\n",
        "\n",
        "    # Stem the words\n",
        "    text = _stem(text)\n",
        "    \n",
        "    #remove stop words\n",
        "    text = _stop(text)\n",
        "\n",
        "    return text\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1rVxQS4dD1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"How are you, Tom? How many works do you have to work?\"\n",
        "print(_removeSymbols(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IULY3OAadD1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"How are you, Tom? How many works do you have to work?\"\n",
        "print(text.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdNkymvRdD1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"How are you, Tom? How many works do you have to work?\"\n",
        "print(_stem(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOV78KWadD1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"How are you, Tom? How many works do you have to work?\"\n",
        "print(_stop(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s9JF5vldQUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSZRvismdD1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"How are you, Tom? How many works do you have to work?\"\n",
        "print(process(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNt9OcwDdD10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Segment Chinese sentence into words\n",
        "import jieba\n",
        "\n",
        "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
        "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyQwf52fdpCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine English words to phrases\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "documents = [\n",
        "    \"the cheif executive officer of new york was there\", \n",
        "    \"machine learning can be useful sometimes\",\n",
        "    \"new york cheif executive officer was present\",\n",
        "    \"machine learning is good\"\n",
        "]\n",
        "\n",
        "sentence_stream = [doc.split(\" \") for doc in documents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY7mW2WmdxSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram = Phraser(Phrases(sentence_stream, min_count=1, threshold=2))\n",
        "\n",
        "for sent in bigram[sentence_stream]:\n",
        "    print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcRb1OQmd1yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trigram = Phraser(Phrases(bigram[sentence_stream], min_count=1, threshold=2))\n",
        "\n",
        "for sent in trigram[bigram[sentence_stream]]:\n",
        "    print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}