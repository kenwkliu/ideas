{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSb-_6hddD1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/kenwkliu/ideas/master/colab/preprocess.py\n",
        "import preprocess\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import treebank\n",
        "nltk.download('treebank')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1rVxQS4dD1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"How are you, Tom? How many works do you have to work?\"\n",
        "print(preprocess._removeSymbols(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IULY3OAadD1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"How are you, Tom? How many works do you have to work?\"\n",
        "print(text.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdNkymvRdD1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"How are you, Tom? How many works do you have to work?\"\n",
        "print(preprocess._stem(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta9VtFZ7JNVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stemming by PorterStemmer\n",
        "# https://www.nltk.org/_modules/nltk/stem/porter.html\n",
        "\n",
        "s = PorterStemmer()\n",
        "print(s.stem('Having'))\n",
        "print(s.stem('Have'))\n",
        "print(s.stem('Had'))\n",
        "\n",
        "print(s.stem('Fishing'))\n",
        "print(s.stem('Fish'))\n",
        "print(s.stem('Fisher'))\n",
        "print(s.stem('Fishes'))\n",
        "print(s.stem('Fished'))\n",
        "\n",
        "print(s.stem('am'))\n",
        "print(s.stem('is'))\n",
        "print(s.stem('was'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0aghCz-JPwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatization by WordNet\n",
        "# Lemmatization is the process of converting a word to its base form. \n",
        "# Lemmatization considers the context and converts the word to its meaningful base form, \n",
        "# whereas stemming just removes the last few characters\n",
        "# Sometimes the same word can have multiple different lemmas. \n",
        "# Based on the context (by POS tag), extract the appropriate lemma.\n",
        "\n",
        "s = WordNetLemmatizer()\n",
        "print(s.lemmatize('having', pos='v'))\n",
        "print(s.lemmatize('have', pos='v'))\n",
        "print(s.lemmatize('had', pos='v'))\n",
        "\n",
        "print(s.lemmatize('fishing', pos='v'))\n",
        "print(s.lemmatize('fish', pos='v'))\n",
        "print(s.lemmatize('fisher', pos='n'))\n",
        "print(s.lemmatize('fishes', pos='v'))\n",
        "print(s.lemmatize('fished', pos='v'))\n",
        "\n",
        "print(s.lemmatize('am', pos='v'))\n",
        "print(s.lemmatize('is', pos='v'))\n",
        "print(s.lemmatize('was', pos='v'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOV78KWadD1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"How are you, Tom? How many works do you have to work?\"\n",
        "print(preprocess._stop(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s9JF5vldQUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess.stop_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSZRvismdD1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"How are you, Tom? How many works do you have to work?\"\n",
        "print(preprocess.process(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNt9OcwDdD10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Segment Chinese sentence into words\n",
        "import jieba\n",
        "\n",
        "TEXT = \"白石角新發展區位於沙田與大埔之間，2012年起發展成住宅區，多個樓盤如天賦海灣、逸瓏灣、海日灣及朗濤等相繼落成及入伙\"\n",
        "\n",
        "seg_list = jieba.cut(TEXT)\n",
        "print(\"/\".join(seg_list))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyQwf52fdpCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine English words to phrases\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "documents = [\n",
        "    \"the cheif executive officer of new york was there\", \n",
        "    \"machine learning can be useful sometimes\",\n",
        "    \"new york cheif executive officer was present\",\n",
        "    \"machine learning is good\"\n",
        "]\n",
        "\n",
        "sentence_stream = [doc.split(\" \") for doc in documents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY7mW2WmdxSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram = Phraser(Phrases(sentence_stream, min_count=1, threshold=2))\n",
        "\n",
        "for sent in bigram[sentence_stream]:\n",
        "    print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcRb1OQmd1yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trigram = Phraser(Phrases(bigram[sentence_stream], min_count=1, threshold=2))\n",
        "\n",
        "for sent in trigram[bigram[sentence_stream]]:\n",
        "    print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyQgUsWnJl0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tree Bank\n",
        "words = treebank.words()\n",
        "\n",
        "# Bi-grams\n",
        "bigrams = nltk.bigrams(words)\n",
        "biFdist = nltk.FreqDist(bigrams)\n",
        "biFdist.plot(20, cumulative=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4hsTp1MJr9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess the words\n",
        "preprocessed = []\n",
        "\n",
        "for w in words:\n",
        "  p = preprocess.process(w)\n",
        "  if len(p)>0: preprocessed.append(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq1jJIVBJtUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigrams = nltk.bigrams(preprocessed)\n",
        "biFdist = nltk.FreqDist(bigrams)\n",
        "biFdist.plot(20, cumulative=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lxdVJaadUrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word cloud\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "MAX_WORDS = 50\n",
        "BG_COLOR = \"black\" # white\n",
        "\n",
        "text = 'this is a word cloud example and I really like this word cloud as word cloud is great'\n",
        "wordcloud = WordCloud(max_words=MAX_WORDS, stopwords='', background_color=BG_COLOR).generate(text)\n",
        "\n",
        "plt.figure(figsize=[15,10])\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy0Edl0-LtWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the word cloud to a file\n",
        "wordcloud.to_file(\"wordcloud.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}