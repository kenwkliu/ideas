{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0suySP9fT7FHsgGpu6Mtk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kenwkliu/ideas/blob/master/colab/GenAI_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8q6_xagJtjQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
        "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ],
      "metadata": {
        "id": "5-5PhzLEMZEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shows a short text sample\n",
        "print(shakespeare_text[:200])"
      ],
      "metadata": {
        "id": "Q2Sz_BoQMrVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
        "                                                   standardize=\"lower\")\n",
        "text_vec_layer.adapt([shakespeare_text])\n",
        "encoded = text_vec_layer([shakespeare_text])[0]\n",
        "\n",
        "encoded -= 2  # drop tokens 0 (pad) and 1 (unknown), which we will not use\n",
        "n_tokens = text_vec_layer.vocabulary_size() - 2  # number of distinct chars = 39\n",
        "dataset_size = len(encoded)  # total number of chars = 1,115,394"
      ],
      "metadata": {
        "id": "QXt8wWm7OMhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(100_000, seed=seed)\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
      ],
      "metadata": {
        "id": "cAYlxDoGX0Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = 100\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True,\n",
        "                       seed=42)\n",
        "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
        "test_set = to_dataset(encoded[1_060_000:], length=length)"
      ],
      "metadata": {
        "id": "pFqjp6ZqYumK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extra code â€“ downloads a pretrained model\n",
        "url = \"https://github.com/ageron/data/raw/main/shakespeare_model.tgz\"\n",
        "path = tf.keras.utils.get_file(\"shakespeare_model.tgz\", url, extract=True)\n",
        "model_path = Path(path).with_name(\"shakespeare_model\")\n",
        "shakespeare_model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "JAOcGaHDYxqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0, -1]\n",
        "y_pred = tf.argmax(y_proba)  # choose the most probable character ID\n",
        "text_vec_layer.get_vocabulary()[y_pred + 2]"
      ],
      "metadata": {
        "id": "MHNZJDh7Zh_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temperature=1):\n",
        "    y_proba = shakespeare_model.predict([text])[0, -1:]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n",
        "    return text_vec_layer.get_vocabulary()[char_id + 2]\n",
        "\n",
        "\n",
        "def extend_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "metadata": {
        "id": "2_ID-_JSZqqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extend_text(\"To be or not to be\", temperature=0.01))"
      ],
      "metadata": {
        "id": "O-m-n8pHZ_Ri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}